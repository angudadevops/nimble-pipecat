{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33ce0a9d-a489-44c7-9168-2d75fb049e42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello vipyne\n"
     ]
    }
   ],
   "source": [
    "print(\"hello vipyne\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ff3d959-5c42-4eb7-b7ee-a0a6f446c5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pipecat-ai in /Users/vipyned/Documents/repos/dailyco/google-bi-di-demo/venv/lib/python3.12/site-packages (0.0.50)\n",
      "Requirement already satisfied: aiohttp~=3.11.9 in /Users/vipyned/Documents/repos/dailyco/google-bi-di-demo/venv/lib/python3.12/site-packages (from pipecat-ai) (3.11.10)\n",
      "Requirement already satisfied: loguru~=0.7.2 in /Users/vipyned/Documents/repos/dailyco/google-bi-di-demo/venv/lib/python3.12/site-packages (from pipecat-ai) (0.7.3)\n",
      "Requirement already satisfied: Markdown~=3.7 in /Users/vipyned/Documents/repos/dailyco/google-bi-di-demo/venv/lib/python3.12/site-packages (from pipecat-ai) (3.7)\n",
      "Requirement already satisfied: numpy~=1.26.4 in /Users/vipyned/Documents/repos/dailyco/google-bi-di-demo/venv/lib/python3.12/site-packages (from pipecat-ai) (1.26.4)\n",
      "Requirement already satisfied: Pillow~=10.4.0 in /Users/vipyned/Documents/repos/dailyco/google-bi-di-demo/venv/lib/python3.12/site-packages (from pipecat-ai) (10.4.0)\n",
      "Requirement already satisfied: protobuf~=5.29.1 in /Users/vipyned/Documents/repos/dailyco/google-bi-di-demo/venv/lib/python3.12/site-packages (from pipecat-ai) (5.29.1)\n",
      "Requirement already satisfied: pydantic~=2.8.2 in /Users/vipyned/Documents/repos/dailyco/google-bi-di-demo/venv/lib/python3.12/site-packages (from pipecat-ai) (2.8.2)\n",
      "Requirement already satisfied: pyloudnorm~=0.1.1 in /Users/vipyned/Documents/repos/dailyco/google-bi-di-demo/venv/lib/python3.12/site-packages (from pipecat-ai) (0.1.1)\n",
      "Requirement already satisfied: resampy~=0.4.3 in /Users/vipyned/Documents/repos/dailyco/google-bi-di-demo/venv/lib/python3.12/site-packages (from pipecat-ai) (0.4.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/vipyned/Documents/repos/dailyco/google-bi-di-demo/venv/lib/python3.12/site-packages (from aiohttp~=3.11.9->pipecat-ai) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/vipyned/Documents/repos/dailyco/google-bi-di-demo/venv/lib/python3.12/site-packages (from aiohttp~=3.11.9->pipecat-ai) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/vipyned/Documents/repos/dailyco/google-bi-di-demo/venv/lib/python3.12/site-packages (from aiohttp~=3.11.9->pipecat-ai) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/vipyned/Documents/repos/dailyco/google-bi-di-demo/venv/lib/python3.12/site-packages (from aiohttp~=3.11.9->pipecat-ai) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/vipyned/Documents/repos/dailyco/google-bi-di-demo/venv/lib/python3.12/site-packages (from aiohttp~=3.11.9->pipecat-ai) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/vipyned/Documents/repos/dailyco/google-bi-di-demo/venv/lib/python3.12/site-packages (from aiohttp~=3.11.9->pipecat-ai) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/vipyned/Documents/repos/dailyco/google-bi-di-demo/venv/lib/python3.12/site-packages (from aiohttp~=3.11.9->pipecat-ai) (1.18.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/vipyned/Documents/repos/dailyco/google-bi-di-demo/venv/lib/python3.12/site-packages (from pydantic~=2.8.2->pipecat-ai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/vipyned/Documents/repos/dailyco/google-bi-di-demo/venv/lib/python3.12/site-packages (from pydantic~=2.8.2->pipecat-ai) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/vipyned/Documents/repos/dailyco/google-bi-di-demo/venv/lib/python3.12/site-packages (from pydantic~=2.8.2->pipecat-ai) (4.12.2)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /Users/vipyned/Documents/repos/dailyco/google-bi-di-demo/venv/lib/python3.12/site-packages (from pyloudnorm~=0.1.1->pipecat-ai) (1.14.1)\n",
      "Requirement already satisfied: future>=0.16.0 in /Users/vipyned/Documents/repos/dailyco/google-bi-di-demo/venv/lib/python3.12/site-packages (from pyloudnorm~=0.1.1->pipecat-ai) (1.0.0)\n",
      "Requirement already satisfied: numba>=0.53 in /Users/vipyned/Documents/repos/dailyco/google-bi-di-demo/venv/lib/python3.12/site-packages (from resampy~=0.4.3->pipecat-ai) (0.60.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /Users/vipyned/Documents/repos/dailyco/google-bi-di-demo/venv/lib/python3.12/site-packages (from numba>=0.53->resampy~=0.4.3->pipecat-ai) (0.43.0)\n",
      "Requirement already satisfied: idna>=2.0 in /Users/vipyned/Documents/repos/dailyco/google-bi-di-demo/venv/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp~=3.11.9->pipecat-ai) (3.10)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pipecat-ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a122332d-9687-46a5-a85b-fd5760d187ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nvidia-riva-client\n",
      "  Downloading nvidia_riva_client-2.17.0-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting setuptools==70.0.0 (from nvidia-riva-client)\n",
      "  Using cached setuptools-70.0.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting grpcio==1.65.4 (from nvidia-riva-client)\n",
      "  Downloading grpcio-1.65.4-cp312-cp312-macosx_10_9_universal2.whl.metadata (3.3 kB)\n",
      "Collecting grpcio-tools==1.65.4 (from nvidia-riva-client)\n",
      "  Downloading grpcio_tools-1.65.4-cp312-cp312-macosx_10_9_universal2.whl.metadata (5.3 kB)\n",
      "Collecting protobuf<6.0dev,>=5.26.1 (from grpcio-tools==1.65.4->nvidia-riva-client)\n",
      "  Using cached protobuf-5.29.1-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
      "Downloading nvidia_riva_client-2.17.0-py3-none-any.whl (46 kB)\n",
      "Downloading grpcio-1.65.4-cp312-cp312-macosx_10_9_universal2.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading grpcio_tools-1.65.4-cp312-cp312-macosx_10_9_universal2.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached setuptools-70.0.0-py3-none-any.whl (863 kB)\n",
      "Using cached protobuf-5.29.1-cp38-abi3-macosx_10_9_universal2.whl (417 kB)\n",
      "Installing collected packages: setuptools, protobuf, grpcio, grpcio-tools, nvidia-riva-client\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.5\n",
      "    Uninstalling protobuf-4.25.5:\n",
      "      Successfully uninstalled protobuf-4.25.5\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.68.1\n",
      "    Uninstalling grpcio-1.68.1:\n",
      "      Successfully uninstalled grpcio-1.68.1\n",
      "Successfully installed grpcio-1.65.4 grpcio-tools-1.65.4 nvidia-riva-client-2.17.0 protobuf-5.29.1 setuptools-70.0.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nvidia-riva-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c426daf3-7fc0-45f2-9746-3801826397d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nest_asyncio in /Users/vipyned/Documents/repos/dailyco/google-bi-di-demo/venv/lib/python3.12/site-packages (1.6.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8e79833-b456-4331-b610-679ea2bed6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-12 13:31:13.281\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.audio.vad.vad_analyzer\u001b[0m:\u001b[36mset_params\u001b[0m:\u001b[36m69\u001b[0m - \u001b[1mSetting VAD params to: confidence=0.7 start_secs=0.2 stop_secs=0.8 min_volume=0.6\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:13.281\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.audio.vad.vad_analyzer\u001b[0m:\u001b[36mset_params\u001b[0m:\u001b[36m69\u001b[0m - \u001b[1mSetting VAD params to: confidence=0.7 start_secs=0.2 stop_secs=0.8 min_volume=0.6\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:13.283\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.audio.vad.silero\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m114\u001b[0m - \u001b[34m\u001b[1mLoading Silero VAD model...\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:13.283\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.audio.vad.silero\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m114\u001b[0m - \u001b[34m\u001b[1mLoading Silero VAD model...\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:13.417\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.audio.vad.silero\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m136\u001b[0m - \u001b[34m\u001b[1mLoaded Silero VAD\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:13.417\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.audio.vad.silero\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m136\u001b[0m - \u001b[34m\u001b[1mLoaded Silero VAD\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:14.775\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking PipelineSource#0 -> DailyInputTransport#0\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:14.775\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking PipelineSource#0 -> DailyInputTransport#0\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:14.776\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking DailyInputTransport#0 -> ParakeetSTTService#0\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:14.776\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking DailyInputTransport#0 -> ParakeetSTTService#0\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:14.778\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking ParakeetSTTService#0 -> OpenAIUserContextAggregator#0\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:14.778\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking ParakeetSTTService#0 -> OpenAIUserContextAggregator#0\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:14.779\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking OpenAIUserContextAggregator#0 -> NimLLMService#0\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:14.779\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking OpenAIUserContextAggregator#0 -> NimLLMService#0\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:14.780\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking NimLLMService#0 -> FastPitchTTSService#0\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:14.780\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking NimLLMService#0 -> FastPitchTTSService#0\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:14.781\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking FastPitchTTSService#0 -> DailyOutputTransport#0\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:14.781\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking FastPitchTTSService#0 -> DailyOutputTransport#0\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:14.782\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking DailyOutputTransport#0 -> OpenAIAssistantContextAggregator#0\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:14.782\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking DailyOutputTransport#0 -> OpenAIAssistantContextAggregator#0\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:14.783\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking OpenAIAssistantContextAggregator#0 -> PipelineSink#0\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:14.783\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking OpenAIAssistantContextAggregator#0 -> PipelineSink#0\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:14.784\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking Source#0 -> Pipeline#0\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:14.784\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking Source#0 -> Pipeline#0\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:14.786\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking Pipeline#0 -> Sink#0\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:14.786\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking Pipeline#0 -> Sink#0\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:14.788\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.pipeline.runner\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m27\u001b[0m - \u001b[34m\u001b[1mRunner PipelineRunner#0 started running PipelineTask#0\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:14.788\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.pipeline.runner\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m27\u001b[0m - \u001b[34m\u001b[1mRunner PipelineRunner#0 started running PipelineTask#0\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:14.790\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.transports.services.daily\u001b[0m:\u001b[36mjoin\u001b[0m:\u001b[36m322\u001b[0m - \u001b[1mJoining https://pc-34b1bdc94a7741719b57b2efb82d658e.daily.co/prod-test\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:14.790\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.transports.services.daily\u001b[0m:\u001b[36mjoin\u001b[0m:\u001b[36m322\u001b[0m - \u001b[1mJoining https://pc-34b1bdc94a7741719b57b2efb82d658e.daily.co/prod-test\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:15.425\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.transports.services.daily\u001b[0m:\u001b[36mon_participant_joined\u001b[0m:\u001b[36m595\u001b[0m - \u001b[1mParticipant joined 1ba6bb85-ded7-47ed-a3c7-66224c686d16\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:15.425\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.transports.services.daily\u001b[0m:\u001b[36mon_participant_joined\u001b[0m:\u001b[36m595\u001b[0m - \u001b[1mParticipant joined 1ba6bb85-ded7-47ed-a3c7-66224c686d16\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:16.145\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.transports.services.daily\u001b[0m:\u001b[36mjoin\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mJoined https://pc-34b1bdc94a7741719b57b2efb82d658e.daily.co/prod-test\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:16.145\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.transports.services.daily\u001b[0m:\u001b[36mjoin\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mJoined https://pc-34b1bdc94a7741719b57b2efb82d658e.daily.co/prod-test\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:16.148\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.openai\u001b[0m:\u001b[36m_stream_chat_completions\u001b[0m:\u001b[36m174\u001b[0m - \u001b[34m\u001b[1mGenerating chat: [{\"role\": \"system\", \"content\": \"You are a helpful LLM in a WebRTC call. Your goal is to demonstrate your capabilities in a succinct way. Your output will be converted to audio so don't include special characters in your answers. Respond to what the user said in a creative and helpful way.\", \"name\": \"system\"}, {\"role\": \"system\", \"content\": \"Please introduce yourself to the user.\", \"name\": \"system\"}]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:16.148\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.openai\u001b[0m:\u001b[36m_stream_chat_completions\u001b[0m:\u001b[36m174\u001b[0m - \u001b[34m\u001b[1mGenerating chat: [{\"role\": \"system\", \"content\": \"You are a helpful LLM in a WebRTC call. Your goal is to demonstrate your capabilities in a succinct way. Your output will be converted to audio so don't include special characters in your answers. Respond to what the user said in a creative and helpful way.\", \"name\": \"system\"}, {\"role\": \"system\", \"content\": \"Please introduce yourself to the user.\", \"name\": \"system\"}]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:16.741\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_input\u001b[0m:\u001b[36m_handle_interruptions\u001b[0m:\u001b[36m124\u001b[0m - \u001b[34m\u001b[1mUser started speaking\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:16.741\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_input\u001b[0m:\u001b[36m_handle_interruptions\u001b[0m:\u001b[36m124\u001b[0m - \u001b[34m\u001b[1mUser started speaking\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:18.579\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_input\u001b[0m:\u001b[36m_handle_interruptions\u001b[0m:\u001b[36m131\u001b[0m - \u001b[34m\u001b[1mUser stopped speaking\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:18.579\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_input\u001b[0m:\u001b[36m_handle_interruptions\u001b[0m:\u001b[36m131\u001b[0m - \u001b[34m\u001b[1mUser stopped speaking\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:18.581\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.openai\u001b[0m:\u001b[36m_stream_chat_completions\u001b[0m:\u001b[36m174\u001b[0m - \u001b[34m\u001b[1mGenerating chat: [{\"role\": \"system\", \"content\": \"You are a helpful LLM in a WebRTC call. Your goal is to demonstrate your capabilities in a succinct way. Your output will be converted to audio so don't include special characters in your answers. Respond to what the user said in a creative and helpful way.\", \"name\": \"system\"}, {\"role\": \"system\", \"content\": \"Please introduce yourself to the user.\", \"name\": \"system\"}, {\"role\": \"user\", \"content\": \"and \"}]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:18.581\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.openai\u001b[0m:\u001b[36m_stream_chat_completions\u001b[0m:\u001b[36m174\u001b[0m - \u001b[34m\u001b[1mGenerating chat: [{\"role\": \"system\", \"content\": \"You are a helpful LLM in a WebRTC call. Your goal is to demonstrate your capabilities in a succinct way. Your output will be converted to audio so don't include special characters in your answers. Respond to what the user said in a creative and helpful way.\", \"name\": \"system\"}, {\"role\": \"system\", \"content\": \"Please introduce yourself to the user.\", \"name\": \"system\"}, {\"role\": \"user\", \"content\": \"and \"}]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:19.419\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_input\u001b[0m:\u001b[36m_handle_interruptions\u001b[0m:\u001b[36m124\u001b[0m - \u001b[34m\u001b[1mUser started speaking\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:19.419\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_input\u001b[0m:\u001b[36m_handle_interruptions\u001b[0m:\u001b[36m124\u001b[0m - \u001b[34m\u001b[1mUser started speaking\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:42.500\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_input\u001b[0m:\u001b[36m_handle_interruptions\u001b[0m:\u001b[36m131\u001b[0m - \u001b[34m\u001b[1mUser stopped speaking\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:42.500\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_input\u001b[0m:\u001b[36m_handle_interruptions\u001b[0m:\u001b[36m131\u001b[0m - \u001b[34m\u001b[1mUser stopped speaking\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:42.502\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.openai\u001b[0m:\u001b[36m_stream_chat_completions\u001b[0m:\u001b[36m174\u001b[0m - \u001b[34m\u001b[1mGenerating chat: [{\"role\": \"system\", \"content\": \"You are a helpful LLM in a WebRTC call. Your goal is to demonstrate your capabilities in a succinct way. Your output will be converted to audio so don't include special characters in your answers. Respond to what the user said in a creative and helpful way.\", \"name\": \"system\"}, {\"role\": \"system\", \"content\": \"Please introduce yourself to the user.\", \"name\": \"system\"}, {\"role\": \"user\", \"content\": \"and \"}, {\"role\": \"user\", \"content\": \"to your point about reviews of course super flexible and available over the holidays so we will just make it work for our technical blog  what is the review process with that is that something since it's on our site  we can draft and take care of it i'm assuming you want eyes on it or  yeah we do have a \"}]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:42.502\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.openai\u001b[0m:\u001b[36m_stream_chat_completions\u001b[0m:\u001b[36m174\u001b[0m - \u001b[34m\u001b[1mGenerating chat: [{\"role\": \"system\", \"content\": \"You are a helpful LLM in a WebRTC call. Your goal is to demonstrate your capabilities in a succinct way. Your output will be converted to audio so don't include special characters in your answers. Respond to what the user said in a creative and helpful way.\", \"name\": \"system\"}, {\"role\": \"system\", \"content\": \"Please introduce yourself to the user.\", \"name\": \"system\"}, {\"role\": \"user\", \"content\": \"and \"}, {\"role\": \"user\", \"content\": \"to your point about reviews of course super flexible and available over the holidays so we will just make it work for our technical blog  what is the review process with that is that something since it's on our site  we can draft and take care of it i'm assuming you want eyes on it or  yeah we do have a \"}]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:42.740\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_input\u001b[0m:\u001b[36m_handle_interruptions\u001b[0m:\u001b[36m124\u001b[0m - \u001b[34m\u001b[1mUser started speaking\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:42.740\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_input\u001b[0m:\u001b[36m_handle_interruptions\u001b[0m:\u001b[36m124\u001b[0m - \u001b[34m\u001b[1mUser started speaking\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:52.020\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_input\u001b[0m:\u001b[36m_handle_interruptions\u001b[0m:\u001b[36m131\u001b[0m - \u001b[34m\u001b[1mUser stopped speaking\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:52.020\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_input\u001b[0m:\u001b[36m_handle_interruptions\u001b[0m:\u001b[36m131\u001b[0m - \u001b[34m\u001b[1mUser stopped speaking\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:52.117\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.openai\u001b[0m:\u001b[36m_stream_chat_completions\u001b[0m:\u001b[36m174\u001b[0m - \u001b[34m\u001b[1mGenerating chat: [{\"role\": \"system\", \"content\": \"You are a helpful LLM in a WebRTC call. Your goal is to demonstrate your capabilities in a succinct way. Your output will be converted to audio so don't include special characters in your answers. Respond to what the user said in a creative and helpful way.\", \"name\": \"system\"}, {\"role\": \"system\", \"content\": \"Please introduce yourself to the user.\", \"name\": \"system\"}, {\"role\": \"user\", \"content\": \"and \"}, {\"role\": \"user\", \"content\": \"to your point about reviews of course super flexible and available over the holidays so we will just make it work for our technical blog  what is the review process with that is that something since it's on our site  we can draft and take care of it i'm assuming you want eyes on it or  yeah we do have a \"}, {\"role\": \"user\", \"content\": \"pr process but to be honest since we have a short run right that's gonna be it's going to be like very accelerated so like once there is a draft \"}]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:52.117\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.openai\u001b[0m:\u001b[36m_stream_chat_completions\u001b[0m:\u001b[36m174\u001b[0m - \u001b[34m\u001b[1mGenerating chat: [{\"role\": \"system\", \"content\": \"You are a helpful LLM in a WebRTC call. Your goal is to demonstrate your capabilities in a succinct way. Your output will be converted to audio so don't include special characters in your answers. Respond to what the user said in a creative and helpful way.\", \"name\": \"system\"}, {\"role\": \"system\", \"content\": \"Please introduce yourself to the user.\", \"name\": \"system\"}, {\"role\": \"user\", \"content\": \"and \"}, {\"role\": \"user\", \"content\": \"to your point about reviews of course super flexible and available over the holidays so we will just make it work for our technical blog  what is the review process with that is that something since it's on our site  we can draft and take care of it i'm assuming you want eyes on it or  yeah we do have a \"}, {\"role\": \"user\", \"content\": \"pr process but to be honest since we have a short run right that's gonna be it's going to be like very accelerated so like once there is a draft \"}]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:52.320\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_input\u001b[0m:\u001b[36m_handle_interruptions\u001b[0m:\u001b[36m124\u001b[0m - \u001b[34m\u001b[1mUser started speaking\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:52.320\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_input\u001b[0m:\u001b[36m_handle_interruptions\u001b[0m:\u001b[36m124\u001b[0m - \u001b[34m\u001b[1mUser started speaking\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:56.760\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_input\u001b[0m:\u001b[36m_handle_interruptions\u001b[0m:\u001b[36m131\u001b[0m - \u001b[34m\u001b[1mUser stopped speaking\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:56.760\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_input\u001b[0m:\u001b[36m_handle_interruptions\u001b[0m:\u001b[36m131\u001b[0m - \u001b[34m\u001b[1mUser stopped speaking\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:56.762\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.openai\u001b[0m:\u001b[36m_stream_chat_completions\u001b[0m:\u001b[36m174\u001b[0m - \u001b[34m\u001b[1mGenerating chat: [{\"role\": \"system\", \"content\": \"You are a helpful LLM in a WebRTC call. Your goal is to demonstrate your capabilities in a succinct way. Your output will be converted to audio so don't include special characters in your answers. Respond to what the user said in a creative and helpful way.\", \"name\": \"system\"}, {\"role\": \"system\", \"content\": \"Please introduce yourself to the user.\", \"name\": \"system\"}, {\"role\": \"user\", \"content\": \"and \"}, {\"role\": \"user\", \"content\": \"to your point about reviews of course super flexible and available over the holidays so we will just make it work for our technical blog  what is the review process with that is that something since it's on our site  we can draft and take care of it i'm assuming you want eyes on it or  yeah we do have a \"}, {\"role\": \"user\", \"content\": \"pr process but to be honest since we have a short run right that's gonna be it's going to be like very accelerated so like once there is a draft \"}, {\"role\": \"user\", \"content\": \"so i think the best we can do is just work backwards from \"}]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:56.762\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.openai\u001b[0m:\u001b[36m_stream_chat_completions\u001b[0m:\u001b[36m174\u001b[0m - \u001b[34m\u001b[1mGenerating chat: [{\"role\": \"system\", \"content\": \"You are a helpful LLM in a WebRTC call. Your goal is to demonstrate your capabilities in a succinct way. Your output will be converted to audio so don't include special characters in your answers. Respond to what the user said in a creative and helpful way.\", \"name\": \"system\"}, {\"role\": \"system\", \"content\": \"Please introduce yourself to the user.\", \"name\": \"system\"}, {\"role\": \"user\", \"content\": \"and \"}, {\"role\": \"user\", \"content\": \"to your point about reviews of course super flexible and available over the holidays so we will just make it work for our technical blog  what is the review process with that is that something since it's on our site  we can draft and take care of it i'm assuming you want eyes on it or  yeah we do have a \"}, {\"role\": \"user\", \"content\": \"pr process but to be honest since we have a short run right that's gonna be it's going to be like very accelerated so like once there is a draft \"}, {\"role\": \"user\", \"content\": \"so i think the best we can do is just work backwards from \"}]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:57.820\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_input\u001b[0m:\u001b[36m_handle_interruptions\u001b[0m:\u001b[36m124\u001b[0m - \u001b[34m\u001b[1mUser started speaking\u001b[0m\n",
      "\u001b[32m2024-12-12 13:31:57.820\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_input\u001b[0m:\u001b[36m_handle_interruptions\u001b[0m:\u001b[36m124\u001b[0m - \u001b[34m\u001b[1mUser started speaking\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:05.310\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_input\u001b[0m:\u001b[36m_handle_interruptions\u001b[0m:\u001b[36m131\u001b[0m - \u001b[34m\u001b[1mUser stopped speaking\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:05.310\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_input\u001b[0m:\u001b[36m_handle_interruptions\u001b[0m:\u001b[36m131\u001b[0m - \u001b[34m\u001b[1mUser stopped speaking\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:05.312\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.openai\u001b[0m:\u001b[36m_stream_chat_completions\u001b[0m:\u001b[36m174\u001b[0m - \u001b[34m\u001b[1mGenerating chat: [{\"role\": \"system\", \"content\": \"You are a helpful LLM in a WebRTC call. Your goal is to demonstrate your capabilities in a succinct way. Your output will be converted to audio so don't include special characters in your answers. Respond to what the user said in a creative and helpful way.\", \"name\": \"system\"}, {\"role\": \"system\", \"content\": \"Please introduce yourself to the user.\", \"name\": \"system\"}, {\"role\": \"user\", \"content\": \"and \"}, {\"role\": \"user\", \"content\": \"to your point about reviews of course super flexible and available over the holidays so we will just make it work for our technical blog  what is the review process with that is that something since it's on our site  we can draft and take care of it i'm assuming you want eyes on it or  yeah we do have a \"}, {\"role\": \"user\", \"content\": \"pr process but to be honest since we have a short run right that's gonna be it's going to be like very accelerated so like once there is a draft \"}, {\"role\": \"user\", \"content\": \"so i think the best we can do is just work backwards from \"}, {\"role\": \"user\", \"content\": \"like what we want to tart to publish the blog and then work backwards from like you know the days off \"}]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:05.312\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.openai\u001b[0m:\u001b[36m_stream_chat_completions\u001b[0m:\u001b[36m174\u001b[0m - \u001b[34m\u001b[1mGenerating chat: [{\"role\": \"system\", \"content\": \"You are a helpful LLM in a WebRTC call. Your goal is to demonstrate your capabilities in a succinct way. Your output will be converted to audio so don't include special characters in your answers. Respond to what the user said in a creative and helpful way.\", \"name\": \"system\"}, {\"role\": \"system\", \"content\": \"Please introduce yourself to the user.\", \"name\": \"system\"}, {\"role\": \"user\", \"content\": \"and \"}, {\"role\": \"user\", \"content\": \"to your point about reviews of course super flexible and available over the holidays so we will just make it work for our technical blog  what is the review process with that is that something since it's on our site  we can draft and take care of it i'm assuming you want eyes on it or  yeah we do have a \"}, {\"role\": \"user\", \"content\": \"pr process but to be honest since we have a short run right that's gonna be it's going to be like very accelerated so like once there is a draft \"}, {\"role\": \"user\", \"content\": \"so i think the best we can do is just work backwards from \"}, {\"role\": \"user\", \"content\": \"like what we want to tart to publish the blog and then work backwards from like you know the days off \"}]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:05.610\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_input\u001b[0m:\u001b[36m_handle_interruptions\u001b[0m:\u001b[36m124\u001b[0m - \u001b[34m\u001b[1mUser started speaking\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:05.610\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_input\u001b[0m:\u001b[36m_handle_interruptions\u001b[0m:\u001b[36m124\u001b[0m - \u001b[34m\u001b[1mUser started speaking\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:07.329\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_input\u001b[0m:\u001b[36m_handle_interruptions\u001b[0m:\u001b[36m131\u001b[0m - \u001b[34m\u001b[1mUser stopped speaking\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:07.329\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_input\u001b[0m:\u001b[36m_handle_interruptions\u001b[0m:\u001b[36m131\u001b[0m - \u001b[34m\u001b[1mUser stopped speaking\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:07.630\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.openai\u001b[0m:\u001b[36m_stream_chat_completions\u001b[0m:\u001b[36m174\u001b[0m - \u001b[34m\u001b[1mGenerating chat: [{\"role\": \"system\", \"content\": \"You are a helpful LLM in a WebRTC call. Your goal is to demonstrate your capabilities in a succinct way. Your output will be converted to audio so don't include special characters in your answers. Respond to what the user said in a creative and helpful way.\", \"name\": \"system\"}, {\"role\": \"system\", \"content\": \"Please introduce yourself to the user.\", \"name\": \"system\"}, {\"role\": \"user\", \"content\": \"and \"}, {\"role\": \"user\", \"content\": \"to your point about reviews of course super flexible and available over the holidays so we will just make it work for our technical blog  what is the review process with that is that something since it's on our site  we can draft and take care of it i'm assuming you want eyes on it or  yeah we do have a \"}, {\"role\": \"user\", \"content\": \"pr process but to be honest since we have a short run right that's gonna be it's going to be like very accelerated so like once there is a draft \"}, {\"role\": \"user\", \"content\": \"so i think the best we can do is just work backwards from \"}, {\"role\": \"user\", \"content\": \"like what we want to tart to publish the blog and then work backwards from like you know the days off \"}, {\"role\": \"user\", \"content\": \"and when it's feasible \"}]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:07.630\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.openai\u001b[0m:\u001b[36m_stream_chat_completions\u001b[0m:\u001b[36m174\u001b[0m - \u001b[34m\u001b[1mGenerating chat: [{\"role\": \"system\", \"content\": \"You are a helpful LLM in a WebRTC call. Your goal is to demonstrate your capabilities in a succinct way. Your output will be converted to audio so don't include special characters in your answers. Respond to what the user said in a creative and helpful way.\", \"name\": \"system\"}, {\"role\": \"system\", \"content\": \"Please introduce yourself to the user.\", \"name\": \"system\"}, {\"role\": \"user\", \"content\": \"and \"}, {\"role\": \"user\", \"content\": \"to your point about reviews of course super flexible and available over the holidays so we will just make it work for our technical blog  what is the review process with that is that something since it's on our site  we can draft and take care of it i'm assuming you want eyes on it or  yeah we do have a \"}, {\"role\": \"user\", \"content\": \"pr process but to be honest since we have a short run right that's gonna be it's going to be like very accelerated so like once there is a draft \"}, {\"role\": \"user\", \"content\": \"so i think the best we can do is just work backwards from \"}, {\"role\": \"user\", \"content\": \"like what we want to tart to publish the blog and then work backwards from like you know the days off \"}, {\"role\": \"user\", \"content\": \"and when it's feasible \"}]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:08.561\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [It seems like we've jumped into a conversation about a technical blog post, its review process, and a tight publication deadline, considering the holiday schedule.]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:08.561\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [It seems like we've jumped into a conversation about a technical blog post, its review process, and a tight publication deadline, considering the holiday schedule.]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:10.316\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_output\u001b[0m:\u001b[36m_bot_started_speaking\u001b[0m:\u001b[36m211\u001b[0m - \u001b[34m\u001b[1mBot started speaking\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:10.316\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_output\u001b[0m:\u001b[36m_bot_started_speaking\u001b[0m:\u001b[36m211\u001b[0m - \u001b[34m\u001b[1mBot started speaking\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:10.318\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ Here's a creative and helpful response tailored to guide the conversation forward:]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:10.318\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ Here's a creative and helpful response tailored to guide the conversation forward:]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:11.195\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [\n",
      "\n",
      "\"Sounds like we're working with a dynamic timeline!]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:11.195\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [\n",
      "\n",
      "\"Sounds like we're working with a dynamic timeline!]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:11.509\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ To ensure a seamless process, let's break down the key steps and milestones for our technical blog post.]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:11.509\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ To ensure a seamless process, let's break down the key steps and milestones for our technical blog post.]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:11.900\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ Given the accelerated schedule, here's a suggested workflow to meet our publication goal:]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:11.900\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ Given the accelerated schedule, here's a suggested workflow to meet our publication goal:]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:12.433\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [\n",
      "\n",
      "1. **Draft Preparation (Your Team)**:]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:12.433\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [\n",
      "\n",
      "1. **Draft Preparation (Your Team)**:]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:13.489\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ Please proceed with drafting the blog post, incorporating all necessary details.]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:13.489\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ Please proceed with drafting the blog post, incorporating all necessary details.]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:14.064\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [\n",
      "2. **Review & Feedback (My End)**:]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:14.064\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [\n",
      "2. **Review & Feedback (My End)**:]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:14.454\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ Once you share the draft, I'll provide a rapid review, focusing on:]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:14.454\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ Once you share the draft, I'll provide a rapid review, focusing on:]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:14.940\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [\n",
      "\t* Technical accuracy\n",
      "\t* Clarity and readability\n",
      "\t* Engagement factors\n",
      "3. **Revisions & Finalization (Collaborative)**:]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:14.940\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [\n",
      "\t* Technical accuracy\n",
      "\t* Clarity and readability\n",
      "\t* Engagement factors\n",
      "3. **Revisions & Finalization (Collaborative)**:]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:15.387\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ We'll work together to address any feedback, ensuring the content meets both our standards.]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:15.387\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ We'll work together to address any feedback, ensuring the content meets both our standards.]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:15.819\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [\n",
      "4. **Publication Readiness (Your Team)**:]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:15.819\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [\n",
      "4. **Publication Readiness (Your Team)**:]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:16.277\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ With the final draft in hand, your team will oversee the publishing process on your site.]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:16.277\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ With the final draft in hand, your team will oversee the publishing process on your site.]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:16.668\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [\n",
      "\n",
      "**Working Backwards from Publication**:]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:16.668\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [\n",
      "\n",
      "**Working Backwards from Publication**:]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:17.026\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [\n",
      "- **Desired Publication Date**:]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:17.026\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [\n",
      "- **Desired Publication Date**:]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:17.391\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ Let's set a specific target date to publish the blog post, considering the upcoming holidays.]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:17.391\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ Let's set a specific target date to publish the blog post, considering the upcoming holidays.]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:18.400\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [\n",
      "- **Draft Submission Deadline**:]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:18.400\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [\n",
      "- **Draft Submission Deadline**:]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:18.788\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ Subtracting review and revision time (approximately 2-3 business days, depending on complexity), we can determine the latest date for draft submission.]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:18.788\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ Subtracting review and revision time (approximately 2-3 business days, depending on complexity), we can determine the latest date for draft submission.]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:19.299\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [\n",
      "- **Current Task**:]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:19.299\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [\n",
      "- **Current Task**:]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:19.674\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ Please share a rough outline or the draft's expected completion date, so we can finalize our timeline.]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:19.674\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ Please share a rough outline or the draft's expected completion date, so we can finalize our timeline.]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:20.418\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [\n",
      "\n",
      "**Holiday Schedule Consideration**:]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:20.418\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [\n",
      "\n",
      "**Holiday Schedule Consideration**:]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:20.801\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [\n",
      "- If there are specific days off that might delay our process, please highlight them, and we'll adjust our timeline accordingly.]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:20.801\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [\n",
      "- If there are specific days off that might delay our process, please highlight them, and we'll adjust our timeline accordingly.]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:21.321\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [\n",
      "\n",
      "**Next Steps**:]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:21.321\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [\n",
      "\n",
      "**Next Steps**:]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:21.640\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [\n",
      "- Confirm the desired publication date.]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:21.640\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [\n",
      "- Confirm the desired publication date.]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:21.951\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [\n",
      "- Share the draft's expected completion date or a preliminary outline.]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:21.951\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [\n",
      "- Share the draft's expected completion date or a preliminary outline.]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:22.288\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [\n",
      "- I'll outline a detailed, date-specific plan for review, feedback, and finalization.]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:22.288\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [\n",
      "- I'll outline a detailed, date-specific plan for review, feedback, and finalization.]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:23.177\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [\n",
      "\n",
      "How does this structured approach sound?]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:23.177\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [\n",
      "\n",
      "How does this structured approach sound?]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:23.570\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ Are there any additional considerations or considerations you'd like to add?]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:23.570\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ Are there any additional considerations or considerations you'd like to add?]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:24.383\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [\"]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:24.383\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [\"]\u001b[0m\n",
      "\u001b[32m2024-12-12 13:32:36.467\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.transports.services.daily\u001b[0m:\u001b[36mon_participant_left\u001b[0m:\u001b[36m605\u001b[0m - \u001b[1mParticipant left 1ba6bb85-ded7-47ed-a3c7-66224c686d16\u001b[0m\n",
      "{\"timestamp\":\"2024-12-12T19:32:36.468049Z\",\"level\":\"ERROR\",\"fields\":{\"message\":\"no subscription for consumer: ConsumerId(\\\"220c13f7-8a08-4be9-a2d2-6bec9f2d0ca7\\\")\"},\"target\":\"daily_core::call_manager::events::from_sfu::soup_consumer_closed\"}\n",
      "\u001b[32m2024-12-12 13:32:36.467\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.transports.services.daily\u001b[0m:\u001b[36mon_participant_left\u001b[0m:\u001b[36m605\u001b[0m - \u001b[1mParticipant left 1ba6bb85-ded7-47ed-a3c7-66224c686d16\u001b[0m\n",
      "{\"timestamp\":\"2024-12-12T19:32:36.535843Z\",\"level\":\"ERROR\",\"fields\":{\"message\":\"Failed to close consumer: ConsumerNoLongerExists(ConsumerId(\\\"220c13f7-8a08-4be9-a2d2-6bec9f2d0ca7\\\"))\"},\"target\":\"daily_core::call_manager::events::subscription::common\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant left: {'id': '1ba6bb85-ded7-47ed-a3c7-66224c686d16', 'info': {'permissions': {'canSend': ['customAudio', 'screenAudio', 'screenVideo', 'customVideo', 'microphone', 'camera'], 'canAdmin': [], 'hasPresence': True}, 'userName': 'vanessa', 'isLocal': False, 'isOwner': False, 'joinedAt': 1734031720}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-12 13:34:43.621\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_output\u001b[0m:\u001b[36m_bot_stopped_speaking\u001b[0m:\u001b[36m218\u001b[0m - \u001b[34m\u001b[1mBot stopped speaking\u001b[0m\n",
      "\u001b[32m2024-12-12 13:34:43.621\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_output\u001b[0m:\u001b[36m_bot_stopped_speaking\u001b[0m:\u001b[36m218\u001b[0m - \u001b[34m\u001b[1mBot stopped speaking\u001b[0m\n",
      "\u001b[32m2024-12-12 13:34:43.622\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.transports.services.daily\u001b[0m:\u001b[36mleave\u001b[0m:\u001b[36m435\u001b[0m - \u001b[1mLeaving https://pc-34b1bdc94a7741719b57b2efb82d658e.daily.co/prod-test\u001b[0m\n",
      "\u001b[32m2024-12-12 13:34:43.622\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.transports.services.daily\u001b[0m:\u001b[36mleave\u001b[0m:\u001b[36m435\u001b[0m - \u001b[1mLeaving https://pc-34b1bdc94a7741719b57b2efb82d658e.daily.co/prod-test\u001b[0m\n",
      "\u001b[32m2024-12-12 13:34:43.638\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.transports.services.daily\u001b[0m:\u001b[36mleave\u001b[0m:\u001b[36m443\u001b[0m - \u001b[1mLeft https://pc-34b1bdc94a7741719b57b2efb82d658e.daily.co/prod-test\u001b[0m\n",
      "\u001b[32m2024-12-12 13:34:43.638\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.transports.services.daily\u001b[0m:\u001b[36mleave\u001b[0m:\u001b[36m443\u001b[0m - \u001b[1mLeft https://pc-34b1bdc94a7741719b57b2efb82d658e.daily.co/prod-test\u001b[0m\n",
      "\u001b[32m2024-12-12 13:34:43.641\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.pipeline.runner\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m31\u001b[0m - \u001b[34m\u001b[1mRunner PipelineRunner#0 finished running PipelineTask#0\u001b[0m\n",
      "\u001b[32m2024-12-12 13:34:43.641\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.pipeline.runner\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m31\u001b[0m - \u001b[34m\u001b[1mRunner PipelineRunner#0 finished running PipelineTask#0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Copyright (c) 2024, Daily\n",
    "#\n",
    "# SPDX-License-Identifier: BSD 2-Clause License\n",
    "#\n",
    "\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "from pipecat.audio.vad.silero import SileroVADAnalyzer\n",
    "from pipecat.frames.frames import LLMMessagesFrame, EndFrame\n",
    "from pipecat.pipeline.pipeline import Pipeline\n",
    "from pipecat.pipeline.runner import PipelineRunner\n",
    "from pipecat.pipeline.task import PipelineParams, PipelineTask\n",
    "from pipecat.processors.aggregators.openai_llm_context import OpenAILLMContext\n",
    "from pipecat.services.nim import NimLLMService\n",
    "from pipecat.services.riva import FastPitchTTSService, ParakeetSTTService\n",
    "from pipecat.transports.services.daily import DailyParams, DailyTransport\n",
    "from pipecat.transports.services.helpers.daily_rest import DailyRESTHelper\n",
    "\n",
    "async def configure(aiohttp_session: aiohttp.ClientSession):\n",
    "    url = os.getenv(\"DAILY_SAMPLE_ROOM_URL\")\n",
    "    key = os.getenv(\"DAILY_API_KEY\")\n",
    "\n",
    "    if not url:\n",
    "        raise Exception(\n",
    "            \"No Daily room specified. use the -u/--url option from the command line, or set DAILY_SAMPLE_ROOM_URL in your environment to specify a Daily room URL.\"\n",
    "        )\n",
    "\n",
    "    if not key:\n",
    "        raise Exception(\n",
    "            \"No Daily API key specified. use the -k/--apikey option from the command line, or set DAILY_API_KEY in your environment to specify a Daily API key, available from https://dashboard.daily.co/developers.\"\n",
    "        )\n",
    "\n",
    "    daily_rest_helper = DailyRESTHelper(\n",
    "        daily_api_key=key,\n",
    "        daily_api_url=os.getenv(\"DAILY_API_URL\", \"https://api.daily.co/v1\"),\n",
    "        aiohttp_session=aiohttp_session,\n",
    "    )\n",
    "\n",
    "    # Create a meeting token for the given room with an expiration 1 hour in\n",
    "    # the future.\n",
    "    expiry_time: float = 60 * 60\n",
    "\n",
    "    token = await daily_rest_helper.get_token(url, expiry_time)\n",
    "\n",
    "    return (url, token)\n",
    "    return (url, token)\n",
    "\n",
    "logger.add(sys.stderr, level=\"DEBUG\")\n",
    "\n",
    "async def main():\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        (room_url, _) = await configure(session)\n",
    "\n",
    "        transport = DailyTransport(\n",
    "            room_url,\n",
    "            None,\n",
    "            \"Respond bot\",\n",
    "            DailyParams(\n",
    "                audio_out_enabled=True,\n",
    "                vad_enabled=True,\n",
    "                vad_analyzer=SileroVADAnalyzer(),\n",
    "                vad_audio_passthrough=True,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        stt = ParakeetSTTService(api_key=os.getenv(\"NVIDIA_API_KEY\"))\n",
    "\n",
    "        llm = NimLLMService(\n",
    "            api_key=os.getenv(\"NVIDIA_API_KEY\")\n",
    "            # api_key=os.getenv(\"NVIDIA_API_KEY\"), model=\"meta/llama-3.1-405b-instruct\"\n",
    "        )\n",
    "\n",
    "        tts = FastPitchTTSService(api_key=os.getenv(\"NVIDIA_API_KEY\"))\n",
    "\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful LLM in a WebRTC call. Your goal is to demonstrate your capabilities in a succinct way. Your output will be converted to audio so don't include special characters in your answers. Respond to what the user said in a creative and helpful way.\",\n",
    "            },\n",
    "        ]\n",
    "\n",
    "        context = OpenAILLMContext(messages)\n",
    "        context_aggregator = llm.create_context_aggregator(context)\n",
    "\n",
    "        pipeline = Pipeline(\n",
    "            [\n",
    "                transport.input(),  # Transport user input\n",
    "                stt,  # STT\n",
    "                context_aggregator.user(),  # User responses\n",
    "                llm,  # LLM\n",
    "                tts,  # TTS\n",
    "                transport.output(),  # Transport bot output\n",
    "                context_aggregator.assistant(),  # Assistant spoken responses\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        task = PipelineTask(pipeline, PipelineParams(allow_interruptions=True))\n",
    "\n",
    "        @transport.event_handler(\"on_first_participant_joined\")\n",
    "        async def on_first_participant_joined(transport, participant):\n",
    "            # Kick off the conversation.\n",
    "            messages.append({\"role\": \"system\", \"content\": \"Please introduce yourself to the user.\"})\n",
    "            await task.queue_frames([LLMMessagesFrame(messages)])\n",
    "\n",
    "        @transport.event_handler(\"on_participant_left\")\n",
    "        async def on_participant_left(transport, participant, reason):\n",
    "            print(f\"Participant left: {participant}\")\n",
    "            await task.queue_frame(EndFrame())            \n",
    "\n",
    "        runner = PipelineRunner()\n",
    "\n",
    "        await runner.run(task)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.12 (i hope)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
