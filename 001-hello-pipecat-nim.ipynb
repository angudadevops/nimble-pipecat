{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1db60caf-a890-4e62-8255-62fd691cd6e6",
   "metadata": {},
   "source": [
    "# Deploy a Voice AI bot with Pipecat AI and NIM (and Riva TTS & STT)\n",
    "In this notebook, we walk through how to craft and deploy a voice AI bot using Pipecat AI. We illustrate the basic Pipecat flow with the `nvidia/llama-3.1-nemotron-70b-instruct` LLM model and Riva for STT (Speech-To-Text) & TTS (Text-To-Speech). However, Pipecat is not opinionated and other models and STT/TTS services can easily be used. See [Pipecat documentation](https://docs.pipecat.ai/server/services/supported-services#supported-services) for other supported services.\n",
    "\n",
    "Pipecat AI is an open-source framework for building voice and multimodal conversational agents. Pipecat simplifies the complex voice-to-voice AI pipeline, and lets developers build AI capabilities easily and with Open Source, commercial, and custom models. See [Pipecat's Core Concepts](https://docs.pipecat.ai/getting-started/core-concepts) for a deep dive into how it works.\n",
    "\n",
    "The framework was developed by Daily, a company that has provided real-time video and audio communication infrastructure since 2016. It is fully vendor neutral and is not tightly coupled to Daily's infrastructure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4fa7d7-88fb-4b33-8145-ee1a91e58af1",
   "metadata": {},
   "source": [
    "## Step 1 - Install dependencies\n",
    "First we set our environment. \n",
    "We use Daily for transport, OpenAI for context aggregation, Riva for TTS & TTS, and Silero for VAD (Voice Activity Detection). If using different services, for example Cartesia for TTS, one would run `pip install pipecat-ai[cartesia]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718d7f76-bb78-4614-ab77-229ed3eea402",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-dotenv\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "!pip install \"pipecat-ai[daily,openai,riva,silero]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7979c5d1-97a9-42e7-9de2-88b7d31b1409",
   "metadata": {},
   "source": [
    "## Step 2 - Configure Daily transport for WebRTC communication\n",
    "- room_url: Where to connect (and where will navigate to to talk to our bot)\n",
    "- None: No authentication token needed\n",
    "- \"NVIDIA NIM\": The bot's display name\n",
    "- Enable audio output for text-to-speech playback and enable VAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe1be9b-e052-4430-b7e1-d7bf57a5ad9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Url to talk to the NVIDIA NIM bot\n",
    "DAILY_SAMPLE_ROOM_URL=\"https://pc-34b1bdc94a7741719b57b2efb82d658e.daily.co/prod-test\"\n",
    "\n",
    "from pipecat.audio.vad.silero import SileroVADAnalyzer\n",
    "from pipecat.transports.services.daily import DailyParams, DailyTransport\n",
    "\n",
    "transport = DailyTransport(\n",
    "    DAILY_SAMPLE_ROOM_URL,\n",
    "    None,\n",
    "    \"NVIDIA NIM\",\n",
    "    DailyParams(\n",
    "        audio_out_enabled=True,\n",
    "        vad_enabled=True,\n",
    "        vad_analyzer=SileroVADAnalyzer(),\n",
    "        vad_audio_passthrough=True,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8506527e-b84c-49e1-8af4-223fdb33f582",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Step 3 - Initialize LLM, STT, and TTS services\n",
    "We can customize options, for example a different LLM `model` or `voice_id` for FastPitch TTS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "623d77d5-c183-43d0-980d-fd99a2836365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pipecat.services.nim import NimLLMService\n",
    "from pipecat.services.riva import FastPitchTTSService, ParakeetSTTService\n",
    "\n",
    "stt = ParakeetSTTService(api_key=os.getenv(\"NVIDIA_API_KEY\"))\n",
    "\n",
    "llm = NimLLMService(\n",
    "    api_key=os.getenv(\"NVIDIA_API_KEY\"), model=\"meta/llama-3.1-70b-instruct\"\n",
    ")\n",
    "\n",
    "tts = FastPitchTTSService(api_key=os.getenv(\"NVIDIA_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac150732-cbb4-4c70-8d31-cab5ae51b5fb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Step 4 - Define prompt and initialize context aggregator\n",
    "Edit the prompt as desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d884775-c4c0-49eb-b502-d4c855cc8e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipecat.processors.aggregators.openai_llm_context import OpenAILLMContext\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful LLM in a WebRTC call. Your goal is to demonstrate your capabilities in a succinct way. Your output will be converted to audio so don't include special characters in your answers. Respond to what the user said in a creative and helpful way that makes a cat pun if it is possible.\",\n",
    "    },\n",
    "]\n",
    "\n",
    "context = OpenAILLMContext(messages)\n",
    "context_aggregator = llm.create_context_aggregator(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c162c265-39cd-49d1-beb6-fcf368572156",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Step 5 - Set event handlers\n",
    "The `on_first_participant_joined` handler tells the bot to start the conversation when you join the call.  \n",
    "The `on_participant_left` handler sends an EndFrame which signals to terminate the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2917234-efc6-440d-b427-ca4acab0b194",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipecat.frames.frames import LLMMessagesFrame, EndFrame\n",
    "\n",
    "@transport.event_handler(\"on_first_participant_joined\")\n",
    "async def on_first_participant_joined(transport, participant):\n",
    "    # Kick off the conversation.\n",
    "    messages.append({\"role\": \"system\", \"content\": \"Please introduce yourself to the user and deliver a cat fact.\"})\n",
    "    await task.queue_frames([LLMMessagesFrame(messages)])\n",
    "\n",
    "@transport.event_handler(\"on_participant_left\")\n",
    "async def on_participant_left(transport, participant, reason):\n",
    "    print(f\"Participant left: {participant}\")\n",
    "    await task.queue_frame(EndFrame())   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1df7a0e-355e-4121-be58-e925e3ea0d16",
   "metadata": {},
   "source": [
    "## Step 6 - Define the Pipecat pipeline\n",
    "Here we align the services into a pipeline to process speech into text, send to llm, then turn the llm response text into speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bec238be-3457-4798-9d47-2afd06c5d94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipecat.pipeline.pipeline import Pipeline\n",
    "from pipecat.pipeline.runner import PipelineRunner\n",
    "from pipecat.pipeline.task import PipelineParams, PipelineTask\n",
    "\n",
    "async def main():\n",
    "    # Create pipeline to process speech into text, send to llm, then turn the llm response text into speech\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            transport.input(),  # Transport user input\n",
    "            stt,  # STT\n",
    "            context_aggregator.user(),  # User responses\n",
    "            llm,  # LLM\n",
    "            tts,  # TTS\n",
    "            transport.output(),  # Transport bot output\n",
    "            context_aggregator.assistant(),  # Assistant spoken responses\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Create PipelineTask\n",
    "    task = PipelineTask(pipeline, PipelineParams(allow_interruptions=True))\n",
    "\n",
    "    # Create a pipeline runner to manage the processing pipeline\n",
    "    runner = PipelineRunner()\n",
    "\n",
    "    await runner.run(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08998f8d-ac33-4b38-b10a-01691f81636a",
   "metadata": {},
   "source": [
    "## Step 7 - Run the bot! Then talk to the bot [HERE](https://pc-34b1bdc94a7741719b57b2efb82d658e.daily.co/prod-test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a411cb-d2c8-4446-be69-b391486e853e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-12 21:38:26.286\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking PipelineSource#0 -> DailyInputTransport#0\u001b[0m\n",
      "\u001b[32m2024-12-12 21:38:26.286\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking PipelineSource#0 -> DailyInputTransport#0\u001b[0m\n",
      "\u001b[32m2024-12-12 21:38:26.287\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking DailyInputTransport#0 -> ParakeetSTTService#0\u001b[0m\n",
      "\u001b[32m2024-12-12 21:38:26.287\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking DailyInputTransport#0 -> ParakeetSTTService#0\u001b[0m\n",
      "\u001b[32m2024-12-12 21:38:26.288\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking ParakeetSTTService#0 -> OpenAIUserContextAggregator#0\u001b[0m\n",
      "\u001b[32m2024-12-12 21:38:26.288\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking ParakeetSTTService#0 -> OpenAIUserContextAggregator#0\u001b[0m\n",
      "\u001b[32m2024-12-12 21:38:26.289\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking OpenAIUserContextAggregator#0 -> NimLLMService#0\u001b[0m\n",
      "\u001b[32m2024-12-12 21:38:26.289\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking OpenAIUserContextAggregator#0 -> NimLLMService#0\u001b[0m\n",
      "\u001b[32m2024-12-12 21:38:26.291\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking NimLLMService#0 -> FastPitchTTSService#0\u001b[0m\n",
      "\u001b[32m2024-12-12 21:38:26.291\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking NimLLMService#0 -> FastPitchTTSService#0\u001b[0m\n",
      "\u001b[32m2024-12-12 21:38:26.292\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking FastPitchTTSService#0 -> DailyOutputTransport#0\u001b[0m\n",
      "\u001b[32m2024-12-12 21:38:26.292\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking FastPitchTTSService#0 -> DailyOutputTransport#0\u001b[0m\n",
      "\u001b[32m2024-12-12 21:38:26.293\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking DailyOutputTransport#0 -> OpenAIAssistantContextAggregator#0\u001b[0m\n",
      "\u001b[32m2024-12-12 21:38:26.293\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking DailyOutputTransport#0 -> OpenAIAssistantContextAggregator#0\u001b[0m\n",
      "\u001b[32m2024-12-12 21:38:26.295\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking OpenAIAssistantContextAggregator#0 -> PipelineSink#0\u001b[0m\n",
      "\u001b[32m2024-12-12 21:38:26.295\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking OpenAIAssistantContextAggregator#0 -> PipelineSink#0\u001b[0m\n",
      "\u001b[32m2024-12-12 21:38:26.296\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking Source#0 -> Pipeline#0\u001b[0m\n",
      "\u001b[32m2024-12-12 21:38:26.296\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking Source#0 -> Pipeline#0\u001b[0m\n",
      "\u001b[32m2024-12-12 21:38:26.297\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking Pipeline#0 -> Sink#0\u001b[0m\n",
      "\u001b[32m2024-12-12 21:38:26.297\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking Pipeline#0 -> Sink#0\u001b[0m\n",
      "\u001b[32m2024-12-12 21:38:26.298\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.pipeline.runner\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m27\u001b[0m - \u001b[34m\u001b[1mRunner PipelineRunner#0 started running PipelineTask#0\u001b[0m\n",
      "\u001b[32m2024-12-12 21:38:26.298\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.pipeline.runner\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m27\u001b[0m - \u001b[34m\u001b[1mRunner PipelineRunner#0 started running PipelineTask#0\u001b[0m\n",
      "\u001b[32m2024-12-12 21:38:26.300\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.transports.services.daily\u001b[0m:\u001b[36mjoin\u001b[0m:\u001b[36m322\u001b[0m - \u001b[1mJoining https://pc-34b1bdc94a7741719b57b2efb82d658e.daily.co/prod-test\u001b[0m\n",
      "\u001b[32m2024-12-12 21:38:26.300\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.transports.services.daily\u001b[0m:\u001b[36mjoin\u001b[0m:\u001b[36m322\u001b[0m - \u001b[1mJoining https://pc-34b1bdc94a7741719b57b2efb82d658e.daily.co/prod-test\u001b[0m\n",
      "\u001b[32m2024-12-12 21:38:28.579\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.transports.services.daily\u001b[0m:\u001b[36mjoin\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mJoined https://pc-34b1bdc94a7741719b57b2efb82d658e.daily.co/prod-test\u001b[0m\n",
      "\u001b[32m2024-12-12 21:38:28.579\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.transports.services.daily\u001b[0m:\u001b[36mjoin\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mJoined https://pc-34b1bdc94a7741719b57b2efb82d658e.daily.co/prod-test\u001b[0m\n",
      "\u001b[32m2024-12-12 21:38:42.465\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.transports.services.daily\u001b[0m:\u001b[36mon_participant_joined\u001b[0m:\u001b[36m595\u001b[0m - \u001b[1mParticipant joined 92f713be-9e1c-4c52-acab-5c4a7dc89132\u001b[0m\n",
      "\u001b[32m2024-12-12 21:38:42.465\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.transports.services.daily\u001b[0m:\u001b[36mon_participant_joined\u001b[0m:\u001b[36m595\u001b[0m - \u001b[1mParticipant joined 92f713be-9e1c-4c52-acab-5c4a7dc89132\u001b[0m\n",
      "\u001b[32m2024-12-12 21:40:59.230\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_input\u001b[0m:\u001b[36m_handle_interruptions\u001b[0m:\u001b[36m124\u001b[0m - \u001b[34m\u001b[1mUser started speaking\u001b[0m\n",
      "\u001b[32m2024-12-12 21:40:59.230\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_input\u001b[0m:\u001b[36m_handle_interruptions\u001b[0m:\u001b[36m124\u001b[0m - \u001b[34m\u001b[1mUser started speaking\u001b[0m\n",
      "\u001b[32m2024-12-12 21:41:00.390\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_input\u001b[0m:\u001b[36m_handle_interruptions\u001b[0m:\u001b[36m131\u001b[0m - \u001b[34m\u001b[1mUser stopped speaking\u001b[0m\n",
      "\u001b[32m2024-12-12 21:41:00.390\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_input\u001b[0m:\u001b[36m_handle_interruptions\u001b[0m:\u001b[36m131\u001b[0m - \u001b[34m\u001b[1mUser stopped speaking\u001b[0m\n",
      "\u001b[32m2024-12-12 21:41:01.362\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.openai\u001b[0m:\u001b[36m_stream_chat_completions\u001b[0m:\u001b[36m174\u001b[0m - \u001b[34m\u001b[1mGenerating chat: [{\"role\": \"system\", \"content\": \"You are a helpful LLM in a WebRTC call. Your goal is to demonstrate your capabilities in a succinct way. Your output will be converted to audio so don't include special characters in your answers. Respond to what the user said in a creative and helpful way that makes a cat pun if it is possible.\"}, {\"role\": \"system\", \"content\": \"Please introduce yourself to the user and deliver a cat fact.\"}, {\"role\": \"user\", \"content\": \"you there \"}]\u001b[0m\n",
      "\u001b[32m2024-12-12 21:41:01.362\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.openai\u001b[0m:\u001b[36m_stream_chat_completions\u001b[0m:\u001b[36m174\u001b[0m - \u001b[34m\u001b[1mGenerating chat: [{\"role\": \"system\", \"content\": \"You are a helpful LLM in a WebRTC call. Your goal is to demonstrate your capabilities in a succinct way. Your output will be converted to audio so don't include special characters in your answers. Respond to what the user said in a creative and helpful way that makes a cat pun if it is possible.\"}, {\"role\": \"system\", \"content\": \"Please introduce yourself to the user and deliver a cat fact.\"}, {\"role\": \"user\", \"content\": \"you there \"}]\u001b[0m\n",
      "\u001b[32m2024-12-12 21:41:02.048\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [I'm here and ready to pounce into action.]\u001b[0m\n",
      "\u001b[32m2024-12-12 21:41:02.048\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [I'm here and ready to pounce into action.]\u001b[0m\n",
      "\u001b[32m2024-12-12 21:41:03.597\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_output\u001b[0m:\u001b[36m_bot_started_speaking\u001b[0m:\u001b[36m211\u001b[0m - \u001b[34m\u001b[1mBot started speaking\u001b[0m\n",
      "\u001b[32m2024-12-12 21:41:03.597\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_output\u001b[0m:\u001b[36m_bot_started_speaking\u001b[0m:\u001b[36m211\u001b[0m - \u001b[34m\u001b[1mBot started speaking\u001b[0m\n",
      "\u001b[32m2024-12-12 21:41:03.599\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ By the way, did you know that a group of cats is called a \"clowder\"?]\u001b[0m\n",
      "\u001b[32m2024-12-12 21:41:03.599\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ By the way, did you know that a group of cats is called a \"clowder\"?]\u001b[0m\n",
      "\u001b[32m2024-12-12 21:41:04.359\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ Let's get started and see how I can claw my way into being helpful for you today.]\u001b[0m\n",
      "\u001b[32m2024-12-12 21:41:04.359\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ Let's get started and see how I can claw my way into being helpful for you today.]\u001b[0m\n",
      "\u001b[32m2024-12-12 21:41:05.004\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ What's on your mind?]\u001b[0m\n",
      "\u001b[32m2024-12-12 21:41:05.004\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ What's on your mind?]\u001b[0m\n",
      "\u001b[32m2024-12-12 21:41:17.680\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_input\u001b[0m:\u001b[36m_handle_interruptions\u001b[0m:\u001b[36m124\u001b[0m - \u001b[34m\u001b[1mUser started speaking\u001b[0m\n",
      "\u001b[32m2024-12-12 21:41:17.680\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_input\u001b[0m:\u001b[36m_handle_interruptions\u001b[0m:\u001b[36m124\u001b[0m - \u001b[34m\u001b[1mUser started speaking\u001b[0m\n",
      "\u001b[32m2024-12-12 21:41:17.684\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_output\u001b[0m:\u001b[36m_bot_stopped_speaking\u001b[0m:\u001b[36m218\u001b[0m - \u001b[34m\u001b[1mBot stopped speaking\u001b[0m\n",
      "\u001b[32m2024-12-12 21:41:17.684\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_output\u001b[0m:\u001b[36m_bot_stopped_speaking\u001b[0m:\u001b[36m218\u001b[0m - \u001b[34m\u001b[1mBot stopped speaking\u001b[0m\n",
      "\u001b[32m2024-12-12 21:41:18.260\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.transports.services.daily\u001b[0m:\u001b[36mon_participant_left\u001b[0m:\u001b[36m605\u001b[0m - \u001b[1mParticipant left 92f713be-9e1c-4c52-acab-5c4a7dc89132\u001b[0m\n",
      "\u001b[32m2024-12-12 21:41:18.260\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.transports.services.daily\u001b[0m:\u001b[36mon_participant_left\u001b[0m:\u001b[36m605\u001b[0m - \u001b[1mParticipant left 92f713be-9e1c-4c52-acab-5c4a7dc89132\u001b[0m\n",
      "{\"timestamp\":\"2024-12-13T03:41:18.267190Z\",\"level\":\"ERROR\",\"fields\":{\"message\":\"no subscription for consumer: ConsumerId(\\\"ee9fa03d-4a67-4a3c-89d3-759d21d14233\\\")\"},\"target\":\"daily_core::call_manager::events::from_sfu::soup_consumer_closed\"}\n",
      "{\"timestamp\":\"2024-12-13T03:41:18.315914Z\",\"level\":\"ERROR\",\"fields\":{\"message\":\"Failed to close consumer: ConsumerNoLongerExists(ConsumerId(\\\"ee9fa03d-4a67-4a3c-89d3-759d21d14233\\\"))\"},\"target\":\"daily_core::call_manager::events::subscription::common\"}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "logger.add(sys.stderr, level=\"DEBUG\")\n",
    "asyncio.run(main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.12",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
