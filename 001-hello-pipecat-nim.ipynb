{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1db60caf-a890-4e62-8255-62fd691cd6e6",
   "metadata": {},
   "source": [
    "# Deploy a Voice AI bot with Pipecat AI and NIM (and Riva TTS & STT)\n",
    "In this notebook, we walk through how to craft and deploy a voice AI bot using Pipecat AI. We illustrate the basic Pipecat flow with the `nvidia/llama-3.1-nemotron-70b-instruct` LLM model and Riva for STT (Speech-To-Text) & TTS (Text-To-Speech). However, Pipecat is not opinionated and other models and TTS/STT services can easily be used. See [Pipecat documentation](https://docs.pipecat.ai/server/services/supported-services#supported-services) for other supported services.\n",
    "\n",
    "Pipecat AI is an open-source framework for building voice and multimodal conversational agents. Pipecat simplifies the complex voice-to-voice AI pipeline, and lets developers build AI capabilities easily and with Open Source, commercial, and custom models. See [Pipecat's Core Concepts](https://docs.pipecat.ai/getting-started/core-concepts) for a deep dive into how it works.\n",
    "\n",
    "The framework was developed by Daily, a company that has provided real-time video and audio communication infrastructure since 2016. It is fully vendor neutral and is not tightly coupled to Daily's infrastructure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4fa7d7-88fb-4b33-8145-ee1a91e58af1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Step 1 - Install dependencies\n",
    "Here we use Daily for transport, OpenAI for context aggregation, Riva for TTS & TTS, and Silero for VAD (Voice Activity Detection). If using different services, for example Cartesia for TTS, one would run `pip install pipecat-ai[cartesia]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "718d7f76-bb78-4614-ab77-229ed3eea402",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1734059531.914686  147023 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pipecat-ai[daily,openai,riva,silero] in ./venv/lib/python3.12/site-packages (0.0.50)\n",
      "Requirement already satisfied: aiohttp~=3.11.9 in ./venv/lib/python3.12/site-packages (from pipecat-ai[daily,openai,riva,silero]) (3.11.10)\n",
      "Requirement already satisfied: loguru~=0.7.2 in ./venv/lib/python3.12/site-packages (from pipecat-ai[daily,openai,riva,silero]) (0.7.3)\n",
      "Requirement already satisfied: Markdown~=3.7 in ./venv/lib/python3.12/site-packages (from pipecat-ai[daily,openai,riva,silero]) (3.7)\n",
      "Requirement already satisfied: numpy~=1.26.4 in ./venv/lib/python3.12/site-packages (from pipecat-ai[daily,openai,riva,silero]) (1.26.4)\n",
      "Requirement already satisfied: Pillow~=10.4.0 in ./venv/lib/python3.12/site-packages (from pipecat-ai[daily,openai,riva,silero]) (10.4.0)\n",
      "Requirement already satisfied: protobuf~=5.29.1 in ./venv/lib/python3.12/site-packages (from pipecat-ai[daily,openai,riva,silero]) (5.29.1)\n",
      "Requirement already satisfied: pydantic~=2.8.2 in ./venv/lib/python3.12/site-packages (from pipecat-ai[daily,openai,riva,silero]) (2.8.2)\n",
      "Requirement already satisfied: pyloudnorm~=0.1.1 in ./venv/lib/python3.12/site-packages (from pipecat-ai[daily,openai,riva,silero]) (0.1.1)\n",
      "Requirement already satisfied: resampy~=0.4.3 in ./venv/lib/python3.12/site-packages (from pipecat-ai[daily,openai,riva,silero]) (0.4.3)\n",
      "Requirement already satisfied: daily-python~=0.13.0 in ./venv/lib/python3.12/site-packages (from pipecat-ai[daily,openai,riva,silero]) (0.13.0)\n",
      "Requirement already satisfied: openai~=1.50.2 in ./venv/lib/python3.12/site-packages (from pipecat-ai[daily,openai,riva,silero]) (1.50.2)\n",
      "Requirement already satisfied: websockets~=13.1 in ./venv/lib/python3.12/site-packages (from pipecat-ai[daily,openai,riva,silero]) (13.1)\n",
      "Requirement already satisfied: python-deepcompare~=1.0.1 in ./venv/lib/python3.12/site-packages (from pipecat-ai[daily,openai,riva,silero]) (1.0.1)\n",
      "Requirement already satisfied: nvidia-riva-client~=2.17.0 in ./venv/lib/python3.12/site-packages (from pipecat-ai[daily,openai,riva,silero]) (2.17.0)\n",
      "Requirement already satisfied: onnxruntime~=1.20.1 in ./venv/lib/python3.12/site-packages (from pipecat-ai[daily,openai,riva,silero]) (1.20.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./venv/lib/python3.12/site-packages (from aiohttp~=3.11.9->pipecat-ai[daily,openai,riva,silero]) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv/lib/python3.12/site-packages (from aiohttp~=3.11.9->pipecat-ai[daily,openai,riva,silero]) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.12/site-packages (from aiohttp~=3.11.9->pipecat-ai[daily,openai,riva,silero]) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.12/site-packages (from aiohttp~=3.11.9->pipecat-ai[daily,openai,riva,silero]) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.12/site-packages (from aiohttp~=3.11.9->pipecat-ai[daily,openai,riva,silero]) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./venv/lib/python3.12/site-packages (from aiohttp~=3.11.9->pipecat-ai[daily,openai,riva,silero]) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./venv/lib/python3.12/site-packages (from aiohttp~=3.11.9->pipecat-ai[daily,openai,riva,silero]) (1.18.3)\n",
      "Requirement already satisfied: setuptools==70.0.0 in ./venv/lib/python3.12/site-packages (from nvidia-riva-client~=2.17.0->pipecat-ai[daily,openai,riva,silero]) (70.0.0)\n",
      "Requirement already satisfied: grpcio==1.65.4 in ./venv/lib/python3.12/site-packages (from nvidia-riva-client~=2.17.0->pipecat-ai[daily,openai,riva,silero]) (1.65.4)\n",
      "Requirement already satisfied: grpcio-tools==1.65.4 in ./venv/lib/python3.12/site-packages (from nvidia-riva-client~=2.17.0->pipecat-ai[daily,openai,riva,silero]) (1.65.4)\n",
      "Requirement already satisfied: coloredlogs in ./venv/lib/python3.12/site-packages (from onnxruntime~=1.20.1->pipecat-ai[daily,openai,riva,silero]) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in ./venv/lib/python3.12/site-packages (from onnxruntime~=1.20.1->pipecat-ai[daily,openai,riva,silero]) (24.3.25)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.12/site-packages (from onnxruntime~=1.20.1->pipecat-ai[daily,openai,riva,silero]) (24.2)\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.12/site-packages (from onnxruntime~=1.20.1->pipecat-ai[daily,openai,riva,silero]) (1.13.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./venv/lib/python3.12/site-packages (from openai~=1.50.2->pipecat-ai[daily,openai,riva,silero]) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./venv/lib/python3.12/site-packages (from openai~=1.50.2->pipecat-ai[daily,openai,riva,silero]) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.12/site-packages (from openai~=1.50.2->pipecat-ai[daily,openai,riva,silero]) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./venv/lib/python3.12/site-packages (from openai~=1.50.2->pipecat-ai[daily,openai,riva,silero]) (0.8.2)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.12/site-packages (from openai~=1.50.2->pipecat-ai[daily,openai,riva,silero]) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./venv/lib/python3.12/site-packages (from openai~=1.50.2->pipecat-ai[daily,openai,riva,silero]) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in ./venv/lib/python3.12/site-packages (from openai~=1.50.2->pipecat-ai[daily,openai,riva,silero]) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./venv/lib/python3.12/site-packages (from pydantic~=2.8.2->pipecat-ai[daily,openai,riva,silero]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./venv/lib/python3.12/site-packages (from pydantic~=2.8.2->pipecat-ai[daily,openai,riva,silero]) (2.20.1)\n",
      "Requirement already satisfied: scipy>=1.0.1 in ./venv/lib/python3.12/site-packages (from pyloudnorm~=0.1.1->pipecat-ai[daily,openai,riva,silero]) (1.14.1)\n",
      "Requirement already satisfied: future>=0.16.0 in ./venv/lib/python3.12/site-packages (from pyloudnorm~=0.1.1->pipecat-ai[daily,openai,riva,silero]) (1.0.0)\n",
      "Requirement already satisfied: numba>=0.53 in ./venv/lib/python3.12/site-packages (from resampy~=0.4.3->pipecat-ai[daily,openai,riva,silero]) (0.60.0)\n",
      "Requirement already satisfied: idna>=2.8 in ./venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai~=1.50.2->pipecat-ai[daily,openai,riva,silero]) (3.10)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai~=1.50.2->pipecat-ai[daily,openai,riva,silero]) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai~=1.50.2->pipecat-ai[daily,openai,riva,silero]) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai~=1.50.2->pipecat-ai[daily,openai,riva,silero]) (0.14.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in ./venv/lib/python3.12/site-packages (from numba>=0.53->resampy~=0.4.3->pipecat-ai[daily,openai,riva,silero]) (0.43.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in ./venv/lib/python3.12/site-packages (from coloredlogs->onnxruntime~=1.20.1->pipecat-ai[daily,openai,riva,silero]) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.12/site-packages (from sympy->onnxruntime~=1.20.1->pipecat-ai[daily,openai,riva,silero]) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pipecat-ai[daily,openai,riva,silero]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7979c5d1-97a9-42e7-9de2-88b7d31b1409",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Step 2 - Configure Daily transport for WebRTC communication\n",
    "- room_url: Where to connect (and where will navigate to to talk to our bot)\n",
    "- None: No authentication token needed\n",
    "- \"NVIDIA NIM\": The bot's display name\n",
    "- Enable audio output for text-to-speech playback and enable VAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfe1be9b-e052-4430-b7e1-d7bf57a5ad9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-12 21:12:20.260\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.audio.vad.vad_analyzer\u001b[0m:\u001b[36mset_params\u001b[0m:\u001b[36m69\u001b[0m - \u001b[1mSetting VAD params to: confidence=0.7 start_secs=0.2 stop_secs=0.8 min_volume=0.6\u001b[0m\n",
      "\u001b[32m2024-12-12 21:12:20.260\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.audio.vad.vad_analyzer\u001b[0m:\u001b[36mset_params\u001b[0m:\u001b[36m69\u001b[0m - \u001b[1mSetting VAD params to: confidence=0.7 start_secs=0.2 stop_secs=0.8 min_volume=0.6\u001b[0m\n",
      "\u001b[32m2024-12-12 21:12:20.260\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.audio.vad.vad_analyzer\u001b[0m:\u001b[36mset_params\u001b[0m:\u001b[36m69\u001b[0m - \u001b[1mSetting VAD params to: confidence=0.7 start_secs=0.2 stop_secs=0.8 min_volume=0.6\u001b[0m\n",
      "\u001b[32m2024-12-12 21:12:20.260\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.audio.vad.vad_analyzer\u001b[0m:\u001b[36mset_params\u001b[0m:\u001b[36m69\u001b[0m - \u001b[1mSetting VAD params to: confidence=0.7 start_secs=0.2 stop_secs=0.8 min_volume=0.6\u001b[0m\n",
      "\u001b[32m2024-12-12 21:12:20.264\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.audio.vad.silero\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m114\u001b[0m - \u001b[34m\u001b[1mLoading Silero VAD model...\u001b[0m\n",
      "\u001b[32m2024-12-12 21:12:20.264\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.audio.vad.silero\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m114\u001b[0m - \u001b[34m\u001b[1mLoading Silero VAD model...\u001b[0m\n",
      "\u001b[32m2024-12-12 21:12:20.264\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.audio.vad.silero\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m114\u001b[0m - \u001b[34m\u001b[1mLoading Silero VAD model...\u001b[0m\n",
      "\u001b[32m2024-12-12 21:12:20.264\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.audio.vad.silero\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m114\u001b[0m - \u001b[34m\u001b[1mLoading Silero VAD model...\u001b[0m\n",
      "\u001b[32m2024-12-12 21:12:20.371\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.audio.vad.silero\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m136\u001b[0m - \u001b[34m\u001b[1mLoaded Silero VAD\u001b[0m\n",
      "\u001b[32m2024-12-12 21:12:20.371\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.audio.vad.silero\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m136\u001b[0m - \u001b[34m\u001b[1mLoaded Silero VAD\u001b[0m\n",
      "\u001b[32m2024-12-12 21:12:20.371\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.audio.vad.silero\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m136\u001b[0m - \u001b[34m\u001b[1mLoaded Silero VAD\u001b[0m\n",
      "\u001b[32m2024-12-12 21:12:20.371\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.audio.vad.silero\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m136\u001b[0m - \u001b[34m\u001b[1mLoaded Silero VAD\u001b[0m\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "unable to select virtual speaker device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpipecat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvad\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msilero\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SileroVADAnalyzer\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpipecat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransports\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdaily\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DailyParams, DailyTransport\n\u001b[0;32m----> 7\u001b[0m transport \u001b[38;5;241m=\u001b[39m \u001b[43mDailyTransport\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mDAILY_SAMPLE_ROOM_URL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNVIDIA NIM\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mDailyParams\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43maudio_out_enabled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvad_enabled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvad_analyzer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSileroVADAnalyzer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvad_audio_passthrough\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/repos/dailyco/nimble-pipecat/venv/lib/python3.12/site-packages/pipecat/transports/services/daily.py:885\u001b[0m, in \u001b[0;36mDailyTransport.__init__\u001b[0;34m(self, room_url, token, bot_name, params, input_name, output_name, loop)\u001b[0m\n\u001b[1;32m    858\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m DailyCallbacks(\n\u001b[1;32m    859\u001b[0m     on_joined\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_joined,\n\u001b[1;32m    860\u001b[0m     on_left\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_left,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    881\u001b[0m     on_recording_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_recording_error,\n\u001b[1;32m    882\u001b[0m )\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_params \u001b[38;5;241m=\u001b[39m params\n\u001b[0;32m--> 885\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client \u001b[38;5;241m=\u001b[39m \u001b[43mDailyTransportClient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroom_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbot_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_loop\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input: DailyInputTransport \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    889\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output: DailyOutputTransport \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/repos/dailyco/nimble-pipecat/venv/lib/python3.12/site-packages/pipecat/transports/services/daily.py:246\u001b[0m, in \u001b[0;36mDailyTransportClient.__init__\u001b[0;34m(self, room_url, token, bot_name, params, callbacks, loop)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_params\u001b[38;5;241m.\u001b[39maudio_in_enabled \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_params\u001b[38;5;241m.\u001b[39mvad_enabled:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_speaker \u001b[38;5;241m=\u001b[39m Daily\u001b[38;5;241m.\u001b[39mcreate_speaker_device(\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_speaker_name(),\n\u001b[1;32m    242\u001b[0m         sample_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_params\u001b[38;5;241m.\u001b[39maudio_in_sample_rate,\n\u001b[1;32m    243\u001b[0m         channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_params\u001b[38;5;241m.\u001b[39maudio_in_channels,\n\u001b[1;32m    244\u001b[0m         non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    245\u001b[0m     )\n\u001b[0;32m--> 246\u001b[0m     \u001b[43mDaily\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_speaker_device\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_speaker_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: unable to select virtual speaker device"
     ]
    }
   ],
   "source": [
    "# Url to talk to the NVIDIA NIM bot\n",
    "DAILY_SAMPLE_ROOM_URL=\"https://pc-34b1bdc94a7741719b57b2efb82d658e.daily.co/prod-test\"\n",
    "\n",
    "from pipecat.audio.vad.silero import SileroVADAnalyzer\n",
    "from pipecat.transports.services.daily import DailyParams, DailyTransport\n",
    "\n",
    "transport = DailyTransport(\n",
    "    DAILY_SAMPLE_ROOM_URL,\n",
    "    None,\n",
    "    \"NVIDIA NIM\",\n",
    "    DailyParams(\n",
    "        audio_out_enabled=True,\n",
    "        vad_enabled=True,\n",
    "        vad_analyzer=SileroVADAnalyzer(),\n",
    "        vad_audio_passthrough=True,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8506527e-b84c-49e1-8af4-223fdb33f582",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Step 3 - Initialize LLM, STT, and TTS services\n",
    "We can customize options, for example a different LLM `model` or `voice_id` for FastPitch TTS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "623d77d5-c183-43d0-980d-fd99a2836365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pipecat.services.nim import NimLLMService\n",
    "from pipecat.services.riva import FastPitchTTSService, ParakeetSTTService\n",
    "\n",
    "stt = ParakeetSTTService(api_key=os.getenv(\"NVIDIA_API_KEY\"))\n",
    "\n",
    "llm = NimLLMService(\n",
    "    api_key=os.getenv(\"NVIDIA_API_KEY\"), model=\"meta/llama-3.1-70b-instruct\"\n",
    ")\n",
    "\n",
    "tts = FastPitchTTSService(api_key=os.getenv(\"NVIDIA_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac150732-cbb4-4c70-8d31-cab5ae51b5fb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Step 4 - Define prompt and initialize context aggregator\n",
    "Edit the prompt as desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d884775-c4c0-49eb-b502-d4c855cc8e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipecat.processors.aggregators.openai_llm_context import OpenAILLMContext\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful LLM in a WebRTC call. Your goal is to demonstrate your capabilities in a succinct way. Your output will be converted to audio so don't include special characters in your answers. Respond to what the user said in a creative and helpful way that makes a cat pun if it is possible.\",\n",
    "    },\n",
    "]\n",
    "\n",
    "context = OpenAILLMContext(messages)\n",
    "context_aggregator = llm.create_context_aggregator(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c162c265-39cd-49d1-beb6-fcf368572156",
   "metadata": {},
   "source": [
    "## Step 5 - Set event handlers\n",
    "The `on_first_participant_joined` handler tells the bot to start the conversation when you join the call.  \n",
    "The `on_participant_left` handler sends an EndFrame which signals to terminate the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2917234-efc6-440d-b427-ca4acab0b194",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipecat.frames.frames import LLMMessagesFrame, EndFrame\n",
    "\n",
    "@transport.event_handler(\"on_first_participant_joined\")\n",
    "async def on_first_participant_joined(transport, participant):\n",
    "    # Kick off the conversation.\n",
    "    messages.append({\"role\": \"system\", \"content\": \"Please introduce yourself to the user and deliver a cat fact.\"})\n",
    "    await task.queue_frames([LLMMessagesFrame(messages)])\n",
    "\n",
    "@transport.event_handler(\"on_participant_left\")\n",
    "async def on_participant_left(transport, participant, reason):\n",
    "    print(f\"Participant left: {participant}\")\n",
    "    await task.queue_frame(EndFrame())   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1df7a0e-355e-4121-be58-e925e3ea0d16",
   "metadata": {},
   "source": [
    "## Step 6 - Define the Pipecat pipeline\n",
    "Here we align the services into a pipeline to process speech into text, send to llm, then turn the llm response text into speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bec238be-3457-4798-9d47-2afd06c5d94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipecat.pipeline.pipeline import Pipeline\n",
    "from pipecat.pipeline.runner import PipelineRunner\n",
    "from pipecat.pipeline.task import PipelineParams, PipelineTask\n",
    "\n",
    "async def main():\n",
    "    # Create pipeline to process speech into text, send to llm, then turn the llm response text into speech\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            transport.input(),  # Transport user input\n",
    "            stt,  # STT\n",
    "            context_aggregator.user(),  # User responses\n",
    "            llm,  # LLM\n",
    "            tts,  # TTS\n",
    "            transport.output(),  # Transport bot output\n",
    "            context_aggregator.assistant(),  # Assistant spoken responses\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Create PipelineTask\n",
    "    task = PipelineTask(pipeline, PipelineParams(allow_interruptions=True))\n",
    "\n",
    "    # Create a pipeline runner to manage the processing pipeline\n",
    "    runner = PipelineRunner()\n",
    "\n",
    "    await runner.run(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08998f8d-ac33-4b38-b10a-01691f81636a",
   "metadata": {},
   "source": [
    "## Step 7 - Run the bot! Then talk to the bot [HERE](https://pc-34b1bdc94a7741719b57b2efb82d658e.daily.co/prod-test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92a411cb-d2c8-4446-be69-b391486e853e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-12 20:46:06.132\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking PipelineSource#1 -> DailyInputTransport#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.132\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking PipelineSource#1 -> DailyInputTransport#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.132\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking PipelineSource#1 -> DailyInputTransport#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.132\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking PipelineSource#1 -> DailyInputTransport#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.135\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking DailyInputTransport#1 -> ParakeetSTTService#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.135\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking DailyInputTransport#1 -> ParakeetSTTService#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.135\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking DailyInputTransport#1 -> ParakeetSTTService#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.135\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking DailyInputTransport#1 -> ParakeetSTTService#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.137\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking ParakeetSTTService#1 -> OpenAIUserContextAggregator#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.137\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking ParakeetSTTService#1 -> OpenAIUserContextAggregator#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.137\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking ParakeetSTTService#1 -> OpenAIUserContextAggregator#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.137\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking ParakeetSTTService#1 -> OpenAIUserContextAggregator#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.139\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking OpenAIUserContextAggregator#1 -> NimLLMService#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.139\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking OpenAIUserContextAggregator#1 -> NimLLMService#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.139\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking OpenAIUserContextAggregator#1 -> NimLLMService#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.139\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking OpenAIUserContextAggregator#1 -> NimLLMService#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.141\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking NimLLMService#1 -> FastPitchTTSService#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.141\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking NimLLMService#1 -> FastPitchTTSService#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.141\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking NimLLMService#1 -> FastPitchTTSService#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.141\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking NimLLMService#1 -> FastPitchTTSService#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.143\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking FastPitchTTSService#1 -> DailyOutputTransport#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.143\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking FastPitchTTSService#1 -> DailyOutputTransport#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.143\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking FastPitchTTSService#1 -> DailyOutputTransport#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.143\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking FastPitchTTSService#1 -> DailyOutputTransport#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.145\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking DailyOutputTransport#1 -> OpenAIAssistantContextAggregator#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.145\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking DailyOutputTransport#1 -> OpenAIAssistantContextAggregator#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.145\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking DailyOutputTransport#1 -> OpenAIAssistantContextAggregator#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.145\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking DailyOutputTransport#1 -> OpenAIAssistantContextAggregator#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.147\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking OpenAIAssistantContextAggregator#1 -> PipelineSink#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.147\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking OpenAIAssistantContextAggregator#1 -> PipelineSink#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.147\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking OpenAIAssistantContextAggregator#1 -> PipelineSink#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.147\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking OpenAIAssistantContextAggregator#1 -> PipelineSink#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.149\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking Source#1 -> Pipeline#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.149\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking Source#1 -> Pipeline#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.149\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking Source#1 -> Pipeline#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.149\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking Source#1 -> Pipeline#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.151\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking Pipeline#1 -> Sink#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.151\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking Pipeline#1 -> Sink#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.151\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking Pipeline#1 -> Sink#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.151\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mLinking Pipeline#1 -> Sink#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.153\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.pipeline.runner\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m27\u001b[0m - \u001b[34m\u001b[1mRunner PipelineRunner#1 started running PipelineTask#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.153\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.pipeline.runner\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m27\u001b[0m - \u001b[34m\u001b[1mRunner PipelineRunner#1 started running PipelineTask#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.153\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.pipeline.runner\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m27\u001b[0m - \u001b[34m\u001b[1mRunner PipelineRunner#1 started running PipelineTask#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.153\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.pipeline.runner\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m27\u001b[0m - \u001b[34m\u001b[1mRunner PipelineRunner#1 started running PipelineTask#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.156\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.transports.services.daily\u001b[0m:\u001b[36mjoin\u001b[0m:\u001b[36m322\u001b[0m - \u001b[1mJoining https://pc-34b1bdc94a7741719b57b2efb82d658e.daily.co/prod-test\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.156\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.transports.services.daily\u001b[0m:\u001b[36mjoin\u001b[0m:\u001b[36m322\u001b[0m - \u001b[1mJoining https://pc-34b1bdc94a7741719b57b2efb82d658e.daily.co/prod-test\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.156\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.transports.services.daily\u001b[0m:\u001b[36mjoin\u001b[0m:\u001b[36m322\u001b[0m - \u001b[1mJoining https://pc-34b1bdc94a7741719b57b2efb82d658e.daily.co/prod-test\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:06.156\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.transports.services.daily\u001b[0m:\u001b[36mjoin\u001b[0m:\u001b[36m322\u001b[0m - \u001b[1mJoining https://pc-34b1bdc94a7741719b57b2efb82d658e.daily.co/prod-test\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:08.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.transports.services.daily\u001b[0m:\u001b[36mjoin\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mJoined https://pc-34b1bdc94a7741719b57b2efb82d658e.daily.co/prod-test\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:08.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.transports.services.daily\u001b[0m:\u001b[36mjoin\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mJoined https://pc-34b1bdc94a7741719b57b2efb82d658e.daily.co/prod-test\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:08.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.transports.services.daily\u001b[0m:\u001b[36mjoin\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mJoined https://pc-34b1bdc94a7741719b57b2efb82d658e.daily.co/prod-test\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:08.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.transports.services.daily\u001b[0m:\u001b[36mjoin\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mJoined https://pc-34b1bdc94a7741719b57b2efb82d658e.daily.co/prod-test\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:12.602\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.transports.services.daily\u001b[0m:\u001b[36mon_participant_joined\u001b[0m:\u001b[36m595\u001b[0m - \u001b[1mParticipant joined aefae6f4-c4b1-4a14-9415-cc0cd04bd8f8\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:12.602\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.transports.services.daily\u001b[0m:\u001b[36mon_participant_joined\u001b[0m:\u001b[36m595\u001b[0m - \u001b[1mParticipant joined aefae6f4-c4b1-4a14-9415-cc0cd04bd8f8\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:12.602\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.transports.services.daily\u001b[0m:\u001b[36mon_participant_joined\u001b[0m:\u001b[36m595\u001b[0m - \u001b[1mParticipant joined aefae6f4-c4b1-4a14-9415-cc0cd04bd8f8\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:12.602\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.transports.services.daily\u001b[0m:\u001b[36mon_participant_joined\u001b[0m:\u001b[36m595\u001b[0m - \u001b[1mParticipant joined aefae6f4-c4b1-4a14-9415-cc0cd04bd8f8\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:12.608\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.openai\u001b[0m:\u001b[36m_stream_chat_completions\u001b[0m:\u001b[36m174\u001b[0m - \u001b[34m\u001b[1mGenerating chat: [{\"role\": \"system\", \"content\": \"You are a helpful LLM in a WebRTC call. Your goal is to demonstrate your capabilities in a succinct way. Your output will be converted to audio so don't include special characters in your answers. Respond to what the user said in a creative and helpful way that makes a cat pun if it is possible.\", \"name\": \"system\"}, {\"role\": \"system\", \"content\": \"Please introduce yourself to the user and deliver a cat fact.\", \"name\": \"system\"}]\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:12.608\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.openai\u001b[0m:\u001b[36m_stream_chat_completions\u001b[0m:\u001b[36m174\u001b[0m - \u001b[34m\u001b[1mGenerating chat: [{\"role\": \"system\", \"content\": \"You are a helpful LLM in a WebRTC call. Your goal is to demonstrate your capabilities in a succinct way. Your output will be converted to audio so don't include special characters in your answers. Respond to what the user said in a creative and helpful way that makes a cat pun if it is possible.\", \"name\": \"system\"}, {\"role\": \"system\", \"content\": \"Please introduce yourself to the user and deliver a cat fact.\", \"name\": \"system\"}]\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:12.608\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.openai\u001b[0m:\u001b[36m_stream_chat_completions\u001b[0m:\u001b[36m174\u001b[0m - \u001b[34m\u001b[1mGenerating chat: [{\"role\": \"system\", \"content\": \"You are a helpful LLM in a WebRTC call. Your goal is to demonstrate your capabilities in a succinct way. Your output will be converted to audio so don't include special characters in your answers. Respond to what the user said in a creative and helpful way that makes a cat pun if it is possible.\", \"name\": \"system\"}, {\"role\": \"system\", \"content\": \"Please introduce yourself to the user and deliver a cat fact.\", \"name\": \"system\"}]\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:12.608\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.openai\u001b[0m:\u001b[36m_stream_chat_completions\u001b[0m:\u001b[36m174\u001b[0m - \u001b[34m\u001b[1mGenerating chat: [{\"role\": \"system\", \"content\": \"You are a helpful LLM in a WebRTC call. Your goal is to demonstrate your capabilities in a succinct way. Your output will be converted to audio so don't include special characters in your answers. Respond to what the user said in a creative and helpful way that makes a cat pun if it is possible.\", \"name\": \"system\"}, {\"role\": \"system\", \"content\": \"Please introduce yourself to the user and deliver a cat fact.\", \"name\": \"system\"}]\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:13.112\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [Hello there, it's great to connect with you.]\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:13.112\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [Hello there, it's great to connect with you.]\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:13.112\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [Hello there, it's great to connect with you.]\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:13.112\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [Hello there, it's great to connect with you.]\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:13.669\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_output\u001b[0m:\u001b[36m_bot_started_speaking\u001b[0m:\u001b[36m211\u001b[0m - \u001b[34m\u001b[1mBot started speaking\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:13.669\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_output\u001b[0m:\u001b[36m_bot_started_speaking\u001b[0m:\u001b[36m211\u001b[0m - \u001b[34m\u001b[1mBot started speaking\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:13.669\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_output\u001b[0m:\u001b[36m_bot_started_speaking\u001b[0m:\u001b[36m211\u001b[0m - \u001b[34m\u001b[1mBot started speaking\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:13.669\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_output\u001b[0m:\u001b[36m_bot_started_speaking\u001b[0m:\u001b[36m211\u001b[0m - \u001b[34m\u001b[1mBot started speaking\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:13.672\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ I'm your friendly AI assistant, here to help you navigate the call and provide some fun facts along the way.]\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:13.672\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ I'm your friendly AI assistant, here to help you navigate the call and provide some fun facts along the way.]\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:13.672\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ I'm your friendly AI assistant, here to help you navigate the call and provide some fun facts along the way.]\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:13.672\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ I'm your friendly AI assistant, here to help you navigate the call and provide some fun facts along the way.]\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:14.214\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ To get us started, did you know that cats have scent glands on their faces?]\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:14.214\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ To get us started, did you know that cats have scent glands on their faces?]\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:14.214\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ To get us started, did you know that cats have scent glands on their faces?]\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:14.214\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ To get us started, did you know that cats have scent glands on their faces?]\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:14.554\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ It's true - they have a unique organ called the vomeronasal organ, or Jacobson's organ, that helps them detect pheromones.]\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:14.554\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ It's true - they have a unique organ called the vomeronasal organ, or Jacobson's organ, that helps them detect pheromones.]\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:14.554\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ It's true - they have a unique organ called the vomeronasal organ, or Jacobson's organ, that helps them detect pheromones.]\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:14.554\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ It's true - they have a unique organ called the vomeronasal organ, or Jacobson's organ, that helps them detect pheromones.]\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:15.063\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ Who knew our feline friends were such purr-fectly informed creatures?]\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:15.063\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ Who knew our feline friends were such purr-fectly informed creatures?]\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:15.063\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ Who knew our feline friends were such purr-fectly informed creatures?]\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:15.063\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ Who knew our feline friends were such purr-fectly informed creatures?]\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:15.444\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ What's on your mind today?]\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:15.444\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ What's on your mind today?]\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:15.444\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ What's on your mind today?]\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:15.444\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.riva\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mGenerating TTS: [ What's on your mind today?]\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:27.941\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.transports.services.daily\u001b[0m:\u001b[36mon_participant_left\u001b[0m:\u001b[36m605\u001b[0m - \u001b[1mParticipant left aefae6f4-c4b1-4a14-9415-cc0cd04bd8f8\u001b[0m\n",
      "{\"timestamp\":\"2024-12-13T02:46:27.941598Z\",\"level\":\"ERROR\",\"fields\":{\"message\":\"no subscription for consumer: ConsumerId(\\\"e06e87c1-af7f-4546-87ea-e03a35357227\\\")\"},\"target\":\"daily_core::call_manager::events::from_sfu::soup_consumer_closed\"}\n",
      "\u001b[32m2024-12-12 20:46:27.941\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.transports.services.daily\u001b[0m:\u001b[36mon_participant_left\u001b[0m:\u001b[36m605\u001b[0m - \u001b[1mParticipant left aefae6f4-c4b1-4a14-9415-cc0cd04bd8f8\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:27.941\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.transports.services.daily\u001b[0m:\u001b[36mon_participant_left\u001b[0m:\u001b[36m605\u001b[0m - \u001b[1mParticipant left aefae6f4-c4b1-4a14-9415-cc0cd04bd8f8\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:27.941\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.transports.services.daily\u001b[0m:\u001b[36mon_participant_left\u001b[0m:\u001b[36m605\u001b[0m - \u001b[1mParticipant left aefae6f4-c4b1-4a14-9415-cc0cd04bd8f8\u001b[0m\n",
      "{\"timestamp\":\"2024-12-13T02:46:27.991811Z\",\"level\":\"ERROR\",\"fields\":{\"message\":\"Failed to close consumer: ConsumerNoLongerExists(ConsumerId(\\\"e06e87c1-af7f-4546-87ea-e03a35357227\\\"))\"},\"target\":\"daily_core::call_manager::events::subscription::common\"}\n",
      "\u001b[32m2024-12-12 20:46:41.974\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_output\u001b[0m:\u001b[36m_bot_stopped_speaking\u001b[0m:\u001b[36m218\u001b[0m - \u001b[34m\u001b[1mBot stopped speaking\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:41.974\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_output\u001b[0m:\u001b[36m_bot_stopped_speaking\u001b[0m:\u001b[36m218\u001b[0m - \u001b[34m\u001b[1mBot stopped speaking\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:41.974\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_output\u001b[0m:\u001b[36m_bot_stopped_speaking\u001b[0m:\u001b[36m218\u001b[0m - \u001b[34m\u001b[1mBot stopped speaking\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:41.974\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_output\u001b[0m:\u001b[36m_bot_stopped_speaking\u001b[0m:\u001b[36m218\u001b[0m - \u001b[34m\u001b[1mBot stopped speaking\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:41.978\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.transports.services.daily\u001b[0m:\u001b[36mleave\u001b[0m:\u001b[36m435\u001b[0m - \u001b[1mLeaving https://pc-34b1bdc94a7741719b57b2efb82d658e.daily.co/prod-test\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:41.978\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.transports.services.daily\u001b[0m:\u001b[36mleave\u001b[0m:\u001b[36m435\u001b[0m - \u001b[1mLeaving https://pc-34b1bdc94a7741719b57b2efb82d658e.daily.co/prod-test\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:41.978\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.transports.services.daily\u001b[0m:\u001b[36mleave\u001b[0m:\u001b[36m435\u001b[0m - \u001b[1mLeaving https://pc-34b1bdc94a7741719b57b2efb82d658e.daily.co/prod-test\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:41.978\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.transports.services.daily\u001b[0m:\u001b[36mleave\u001b[0m:\u001b[36m435\u001b[0m - \u001b[1mLeaving https://pc-34b1bdc94a7741719b57b2efb82d658e.daily.co/prod-test\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:41.988\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.transports.services.daily\u001b[0m:\u001b[36mleave\u001b[0m:\u001b[36m443\u001b[0m - \u001b[1mLeft https://pc-34b1bdc94a7741719b57b2efb82d658e.daily.co/prod-test\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:41.988\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.transports.services.daily\u001b[0m:\u001b[36mleave\u001b[0m:\u001b[36m443\u001b[0m - \u001b[1mLeft https://pc-34b1bdc94a7741719b57b2efb82d658e.daily.co/prod-test\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:41.988\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.transports.services.daily\u001b[0m:\u001b[36mleave\u001b[0m:\u001b[36m443\u001b[0m - \u001b[1mLeft https://pc-34b1bdc94a7741719b57b2efb82d658e.daily.co/prod-test\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:41.988\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipecat.transports.services.daily\u001b[0m:\u001b[36mleave\u001b[0m:\u001b[36m443\u001b[0m - \u001b[1mLeft https://pc-34b1bdc94a7741719b57b2efb82d658e.daily.co/prod-test\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:41.992\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.pipeline.runner\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m31\u001b[0m - \u001b[34m\u001b[1mRunner PipelineRunner#1 finished running PipelineTask#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:41.992\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.pipeline.runner\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m31\u001b[0m - \u001b[34m\u001b[1mRunner PipelineRunner#1 finished running PipelineTask#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:41.992\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.pipeline.runner\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m31\u001b[0m - \u001b[34m\u001b[1mRunner PipelineRunner#1 finished running PipelineTask#1\u001b[0m\n",
      "\u001b[32m2024-12-12 20:46:41.992\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.pipeline.runner\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m31\u001b[0m - \u001b[34m\u001b[1mRunner PipelineRunner#1 finished running PipelineTask#1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "logger.add(sys.stderr, level=\"DEBUG\")\n",
    "asyncio.run(main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.12",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
